# NYC Taxi Graph Mining - Massive Data Mining Project

## ğŸ“Œ Tá»•ng quan

Dá»± Ã¡n phÃ¢n tÃ­ch Ä‘á»“ thá»‹ giao thÃ´ng taxi NYC quy mÃ´ lá»›n (~30GB dá»¯ liá»‡u) sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n Graph Mining phÃ¢n tÃ¡n.

**Má»¥c tiÃªu:**
- XÃ¢y dá»±ng Ä‘á»“ thá»‹ giao thÃ´ng tá»« 200-300 triá»‡u chuyáº¿n taxi
- TÃ­nh PageRank Ä‘á»ƒ xÃ¡c Ä‘á»‹nh taxi zones quan trá»ng nháº¥t
- PhÃ¡t hiá»‡n communities (clusters) cá»§a cÃ¡c zones
- Chá»©ng minh scalability trÃªn cluster phÃ¢n tÃ¡n

**Dataset:** NYC TLC Yellow Taxi Trip Records (2019-2020)

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HDFS Layer                        â”‚
â”‚  - Raw Data (~30GB Parquet files)                   â”‚
â”‚  - Processed Edge List                               â”‚
â”‚  - Results (PageRank, Communities)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Spark Processing Layer                  â”‚
â”‚  - MapReduce: Build Graph                           â”‚
â”‚  - GraphX: PageRank Algorithm                       â”‚
â”‚  - GraphFrames: Community Detection                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Visualization Layer                   â”‚
â”‚  - Matplotlib/Seaborn Charts                        â”‚
â”‚  - Summary Statistics                                â”‚
â”‚  - Reports                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cluster Setup:**
- Master Node (Ubuntu VM): 6GB RAM, 2-4 CPU cores
- Worker Node (Ubuntu VM): 4GB RAM, 2 CPU cores
- HDFS replication: 2
- Spark Standalone Mode

---

## ğŸ“‚ Cáº¥u trÃºc project

```
massive_data_mining/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ spark_config.py          # Cáº¥u hÃ¬nh Spark session
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                 # Utility functions
â”‚   â”œâ”€â”€ 1_build_graph.py         # BÆ°á»›c 1: XÃ¢y dá»±ng edge list
â”‚   â”œâ”€â”€ 2_pagerank.py            # BÆ°á»›c 2: TÃ­nh PageRank
â”‚   â”œâ”€â”€ 3_clustering.py          # BÆ°á»›c 3: Graph clustering
â”‚   â”œâ”€â”€ 4_visualization.py       # BÆ°á»›c 4: Visualizations
â”‚   â””â”€â”€ 5_benchmark.py           # BÆ°á»›c 5: Benchmark
â”œâ”€â”€ results/                      # Káº¿t quáº£ output
â”‚   â”œâ”€â”€ visualizations/          # Charts vÃ  graphs
â”‚   â””â”€â”€ benchmarks/              # Benchmark results
â”œâ”€â”€ notebooks/                    # Jupyter notebooks (optional)
â”œâ”€â”€ setup_guide.md               # HÆ°á»›ng dáº«n cÃ i Ä‘áº·t chi tiáº¿t
â”œâ”€â”€ intruction.md                # Äá» bÃ i gá»‘c
â””â”€â”€ README.md                    # File nÃ y
```

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### BÆ°á»›c 1: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

**Chi tiáº¿t xem file: `setup_guide.md`**

TÃ³m táº¯t:
1. CÃ i Ä‘áº·t 2 mÃ¡y áº£o Ubuntu trÃªn VMware
2. CÃ i Ä‘áº·t Hadoop cluster (HDFS + YARN)
3. CÃ i Ä‘áº·t Spark cluster
4. CÃ i Ä‘áº·t GraphFrames
5. Thiáº¿t láº­p SSH passwordless giá»¯a cÃ¡c nodes

### BÆ°á»›c 2: Download vÃ  upload dá»¯ liá»‡u

```bash
# TrÃªn master node
cd ~
mkdir nyc_taxi_data

# Download dá»¯ liá»‡u (2019-2020)
for year in 2019 2020; do
    for month in {01..12}; do
        wget "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_${year}-${month}.parquet"
    done
done

# Upload lÃªn HDFS
hdfs dfs -mkdir -p /user/taxi/raw_data
hdfs dfs -put *.parquet /user/taxi/raw_data/

# Kiá»ƒm tra
hdfs dfs -ls /user/taxi/raw_data/
```

### BÆ°á»›c 3: Cháº¡y cÃ¡c bÆ°á»›c processing

**TrÃªn master node:**

```bash
cd massive_data_mining/src

# BÆ°á»›c 1: Build graph (edge list)
spark-submit --master spark://master:7077 \
    --executor-memory 2g \
    --driver-memory 2g \
    --packages graphframes:graphframes:0.8.3-spark3.5-s_2.12 \
    1_build_graph.py

# BÆ°á»›c 2: TÃ­nh PageRank
spark-submit --master spark://master:7077 \
    --executor-memory 2g \
    --driver-memory 2g \
    --packages graphframes:graphframes:0.8.3-spark3.5-s_2.12 \
    2_pagerank.py

# BÆ°á»›c 3: Graph clustering
spark-submit --master spark://master:7077 \
    --executor-memory 2g \
    --driver-memory 2g \
    --packages graphframes:graphframes:0.8.3-spark3.5-s_2.12 \
    3_clustering.py

# BÆ°á»›c 4: Visualization (cháº¡y local)
python3 4_visualization.py

# BÆ°á»›c 5: Benchmark
spark-submit --master spark://master:7077 \
    --executor-memory 2g \
    --driver-memory 2g \
    --packages graphframes:graphframes:0.8.3-spark3.5-s_2.12 \
    5_benchmark.py
```

### BÆ°á»›c 4: Xem káº¿t quáº£

```bash
# Download káº¿t quáº£ tá»« HDFS vá» local
hdfs dfs -get /user/taxi/results/ ../results/hdfs_results/

# Xem visualizations
cd ../results/visualizations/
ls -lh

# Xem summary
cat summary_statistics.csv
cat top50_zones_detailed.csv
```

---

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

### 1. Edge List
- ~50-100 triá»‡u edges (cáº·p zones cÃ³ trip)
- Trá»ng sá»‘ = sá»‘ chuyáº¿n taxi giá»¯a 2 zones
- Format: `(src_zone, dst_zone, trip_count, total_fare, avg_distance)`

### 2. PageRank Results
- Xáº¿p háº¡ng 260 taxi zones theo importance
- Top zones: Manhattan CBD, airports (JFK, LaGuardia)
- PhÃ¢n phá»‘i power-law (vÃ i zones ráº¥t cao, nhiá»u zones tháº¥p)

### 3. Communities
- 20-50 communities Ä‘Æ°á»£c phÃ¡t hiá»‡n
- Má»—i community = nhÃ³m zones cÃ³ giao thÃ´ng ná»™i bá»™ cháº·t cháº½
- CÃ³ thá»ƒ map vá»›i cÃ¡c khu vá»±c Ä‘á»‹a lÃ½ thá»±c táº¿

### 4. Visualizations
- Histogram phÃ¢n phá»‘i PageRank
- Bar chart top zones
- Community size distribution
- Scatter plots

### 5. Benchmark
- So sÃ¡nh runtime 1M vs 10M rows
- Äo speedup khi dÃ¹ng cluster vs single node
- Chá»©ng minh scalability

---

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

**1. Out of Memory**
```bash
# Giáº£m executor memory trong spark-submit
--executor-memory 1g
--driver-memory 1g

# TÄƒng sá»‘ partitions
spark.sql.shuffle.partitions 400
```

**2. HDFS connection refused**
```bash
# Kiá»ƒm tra HDFS Ä‘ang cháº¡y
jps  # Pháº£i tháº¥y NameNode, DataNode

# Restart náº¿u cáº§n
stop-dfs.sh
start-dfs.sh

# Kiá»ƒm tra Web UI
http://master:9870
```

**3. Spark worker khÃ´ng connect**
```bash
# Kiá»ƒm tra SSH passwordless
ssh worker1

# Kiá»ƒm tra /etc/hosts
cat /etc/hosts  # Pháº£i cÃ³ entry cho master vÃ  worker

# Restart Spark
stop-master.sh
stop-workers.sh
start-master.sh
start-workers.sh
```

**4. GraphFrames not found**
```bash
# Äáº£m báº£o dÃ¹ng --packages trong spark-submit
--packages graphframes:graphframes:0.8.3-spark3.5-s_2.12

# Hoáº·c copy JAR vÃ o $SPARK_HOME/jars/
```

---

## ğŸ“ˆ Performance Tips

### Tá»‘i Æ°u cho RAM háº¡n cháº¿

1. **TÄƒng sá»‘ partitions:**
   ```python
   df.repartition(200)
   ```

2. **Unpersist khÃ´ng cáº§n thiáº¿t:**
   ```python
   df.unpersist()
   ```

3. **Sá»­ dá»¥ng broadcast cho small tables:**
   ```python
   from pyspark.sql.functions import broadcast
   large_df.join(broadcast(small_df), ...)
   ```

4. **Checkpoint cho iterative algorithms:**
   ```python
   sc.setCheckpointDir("/tmp/checkpoints")
   rdd.checkpoint()
   ```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

### Há»c thuáº­t
- **Mining of Massive Datasets** - Leskovec, Rajaraman, Ullman (CS246 textbook)
- **PageRank Algorithm** - Page & Brin, 1998
- **Label Propagation** - Raghavan et al., 2007

### Ká»¹ thuáº­t
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [GraphFrames User Guide](https://graphframes.github.io/graphframes/docs/_site/user-guide.html)
- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

### Hadoop/HDFS
- [Hadoop Documentation](https://hadoop.apache.org/docs/stable/)
- [HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

---

## âœ… Checklist cho bÃ¡o cÃ¡o

- [ ] MÃ´ táº£ bÃ i toÃ¡n vÃ  dataset
- [ ] Giáº£i thÃ­ch vÃ¬ sao "massive" (khÃ´ng cháº¡y Ä‘Æ°á»£c trÃªn PC)
- [ ] MÃ´ hÃ¬nh hÃ³a thÃ nh Ä‘á»“ thá»‹ (nodes, edges, weights)
- [ ] Giáº£i thÃ­ch thuáº­t toÃ¡n PageRank
- [ ] CÃ´ng thá»©c toÃ¡n há»c (LaTeX)
- [ ] Pseudocode MapReduce
- [ ] Káº¿t quáº£ PageRank (top zones, phÃ¢n phá»‘i)
- [ ] Káº¿t quáº£ Community Detection
- [ ] Visualization (charts, graphs)
- [ ] Benchmark vÃ  scalability analysis
- [ ] So sÃ¡nh 1 node vs 2 nodes (runtime, memory)
- [ ] Káº¿t luáº­n vÃ  insight

---

## ğŸ‘¥ ThÃ´ng tin nhÃ³m

**TÃªn Ä‘á» tÃ i:** Graph-based Clustering cÃ¡c Taxi Zone tá»« NYC TLC Yellow Taxi Data

**MÃ´n há»c:** Mining of Massive Data (MMDS)

**CÃ´ng nghá»‡:**
- Apache Hadoop 3.3.6
- Apache Spark 3.5.0
- GraphFrames 0.8.3
- Python 3, PySpark

**Cluster:**
- 2 nodes Ubuntu VMs (VMware)
- Total RAM: 10GB
- HDFS replication: 2

---

## ğŸ“ License

Educational project for Mining of Massive Data course.

---

## ğŸ™ Acknowledgments

- NYC Taxi & Limousine Commission for open data
- CS246 course materials (Stanford)
- Apache Spark and GraphFrames communities

---

**Last updated:** 2026-02-04
